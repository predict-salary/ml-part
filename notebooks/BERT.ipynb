{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec4ed79-4c8c-4eaf-9340-ded924098d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from typing import List, Dict, Optional, Literal, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from pytorch_tabular.tabular_datamodule import TabularDataset\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import FTTransformerConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    "    ExperimentConfig,\n",
    ")\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.utils import get_balanced_sampler, get_class_weighted_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef957b27-1e79-4aca-b7e1-dd6b50f97fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(47)\n",
    "np.random.seed(47)\n",
    "torch.cuda.manual_seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a79aea4-8678-4119-845e-9b75c0092c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8452fafa-ff31-4b53-9271-6fef18ddef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cointegrated/rubert-tiny2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f6a7c6-2597-4604-94df-a7308f007eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./saved_models/tabular_class.pkl\", \"rb\") as f:\n",
    "    tabular_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13896089-589d-450e-92be-86eb38eb5134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work_schedule', 'city', 'accredit_it', 'state', 'salary_currency', 'salary_gross', 'vacancy_experience', 'vacancy_type', 'created_quarter', 'created_month', 'trusted']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.datamodule.config.categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7681222a-1214-425c-9c0e-92f3f346b688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': array([1], dtype=int64),\n",
       " 'continuous': array([-0.5090045 ,  0.14593425], dtype=float32),\n",
       " 'categorical': array([1, 3, 2, 1, 1, 2, 2, 1, 1, 1, 1], dtype=int64)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TabularDataset(\n",
    "            task=tabular_model.datamodule.config.task,\n",
    "            data=tabular_model.datamodule._prepare_inference_data(df),\n",
    "            categorical_cols=tabular_model.datamodule.config.categorical_cols,\n",
    "            continuous_cols=tabular_model.datamodule.config.continuous_cols,\n",
    "            target=\"target\"\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67fd3c-4358-45da-bbbe-38ddbc9eade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'vacancy_name_score': {0: 17.0}, 'vacancy_name_len': {0: 22}, 'work_schedule': {0: 'flexible'}, 'city': {0: 'Москва'}, 'accredit_it': {0: False}, 'state': {0: 'APPROVED'}, 'salary_currency': {0: 'RUR'}, 'salary_gross': {0: False}, 'vacancy_experience': {0: 'noExperience'}, 'vacancy_type': {0: 'open'}, 'created_quarter': {0: 1}, 'created_month': {0: 3}, 'trusted': {0: True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b875841-6d45-4704-acf9-6b0e3dbf521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {'vacancy_name_score': [17.0], 'vacancy_name_len': [22], 'work_schedule': ['flexible'], 'city': ['Москва'], 'accredit_it': [False], 'state': ['APPROVED'], 'salary_currency': ['RUR'], 'salary_gross': [False], 'vacancy_experience': ['noExperience'], 'vacancy_type': ['open'], 'created_quarter': [None], 'created_month': [None], 'trusted': [True], 'vacancy_name': ['Видеооператор-монтажер'], 'created_date': [3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636400bc-6ffb-4c27-b48e-3787308d655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be78fb7c-d39e-47b7-a7da-c66de576fbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vacancy_name_score', 'vacancy_name_len']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.datamodule.config.continuous_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800e9c8-3240-4224-b2e6-c356e25d7954",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9254b6f5-6644-4d5b-bf7c-9511a4fd5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_with_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc33ef49-f468-4895-afe3-9da0607d0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"vacancy_name_score\", \"vacancy_name_len\"]\n",
    "categorical_features = [\n",
    "                        \"work_schedule\", \"city\", \"accredit_it\", \"state\",\n",
    "                        \"salary_currency\", \"salary_gross\", \"vacancy_experience\", \"vacancy_type\", \"created_quarter\",\n",
    "                        \"created_month\", \"trusted\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fedd3ab-b6aa-4068-bbf5-135ed832b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"text\"] = [str(i).replace(\"{\", \"\").replace(\"}\", \"\") for i in df[numeric_features + categorical_features].to_dict(\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b007a2-754d-4ae0-859b-c1a2ba8155f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a394e5-e081-4dae-87ad-36e845ed89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"len_description\"] = df[\"vacancy_description\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde98e76-1a5a-4b7a-b2a8-c71a5835f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions = df[[\"len_description\", \"vacancy_description\"]].sort_values(\"len_description\", ascending=False)[\"vacancy_description\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea212a2-1a5f-45c9-8822-3246b3eb1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_exists = os.path.isfile(\"tokens_desc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a321e78-6bb1-40ad-b138-a081c4ad8d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if not file_exists:\n",
    "#     tokens_desc = []\n",
    "\n",
    "#     for i, desc in enumerate(tqdm(descriptions)):\n",
    "#         temp_result = tokenizer(desc, padding=\"max_length\", return_tensors=\"pt\")\n",
    "#         tokens_desc.append(truncer(temp_result))\n",
    "        \n",
    "#     with open(\"tokens_desc.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(tokens_desc, f)\n",
    "# else:\n",
    "#     with open(\"tokens_desc.pkl\", \"rb\") as f:\n",
    "#         tokens_desc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab965be0-61b6-4dc2-9ba1-f29da1589937",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Define custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d394d1eb-47e3-4e67-b145-b7ab059d4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVacancyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tabular_dataset: TabularDataset,\n",
    "        tokenizer,\n",
    "        device: torch.device,\n",
    "        text: str,\n",
    "        target: str,\n",
    "        mode: Optional[Literal[\"train\", \"valid\", \"test\"]] = None,\n",
    "        chunk_size: int = 1024\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.tabular_dataset = tabular_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.mode = mode\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @staticmethod\n",
    "    def chunker(tokens: Dict[str, torch.Tensor], chunk_size: int = 512) -> List[str]:\n",
    "        input_ids = list(tokens[\"input_ids\"][0].split(chunk_size - 2))\n",
    "        attention_mask = list(tokens[\"attention_mask\"][0].split(chunk_size - 2))\n",
    "\n",
    "        cls_token_id = 2\n",
    "        eos_token_id = 3\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            input_ids[i] = torch.cat([torch.Tensor([cls_token_id]), input_ids[i], torch.Tensor([eos_token_id])])\n",
    "            attention_mask[i] = torch.cat([torch.Tensor([1]), attention_mask[i], torch.Tensor([1])])\n",
    "\n",
    "            pad_len = chunk_size - len(input_ids[i])\n",
    "            if pad_len > 0:\n",
    "                input_ids[i]= torch.cat([input_ids[i], torch.Tensor([0]*pad_len)])\n",
    "                attention_mask[i] = torch.cat([attention_mask[i], torch.Tensor([0]*pad_len)])\n",
    "                \n",
    "        tokens[\"input_ids\"] = torch.stack(input_ids)\n",
    "        tokens[\"attention_mask\"] = torch.stack(attention_mask)\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        tokens = self.tokenizer(self.data.iloc[idx][self.text], return_tensors=\"pt\", add_special_tokens=False, return_token_type_ids=False)\n",
    "        tokens = self.chunker(tokens, self.chunk_size)\n",
    "        \n",
    "        tokens[\"input_ids\"] = tokens[\"input_ids\"].to(device).long()\n",
    "        tokens[\"attention_mask\"] = tokens[\"attention_mask\"].to(device).int()\n",
    "        \n",
    "        if self.mode == \"test\":\n",
    "            return tokens, self.tabular_dataset[idx]\n",
    "\n",
    "        label = self.data.iloc[idx][self.target]\n",
    "        return tokens, torch.tensor(label), self.tabular_dataset[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f6ac8-ced1-424d-9a8e-d02e8421d0fa",
   "metadata": {},
   "source": [
    "# Define train, valid, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "879a1d89-56e1-4a1f-b132-6a7119ac1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df29535-6e76-4350-a592-9bbb07de4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, shuffle=True, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e894466a-3f8b-491d-b183-17a65c81e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, test = train_test_split(valid, shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d867f93-9708-4162-a2b8-54a608a45f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tabular_dataset = TabularDataset(\n",
    "            task=tabular_model.datamodule.config.task,\n",
    "            data=tabular_model.datamodule._prepare_inference_data(train),\n",
    "            categorical_cols=tabular_model.datamodule.config.categorical_cols,\n",
    "            continuous_cols=tabular_model.datamodule.config.continuous_cols,\n",
    "            target=\"target\"\n",
    "    )\n",
    "\n",
    "valid_tabular_dataset = TabularDataset(\n",
    "            task=tabular_model.datamodule.config.task,\n",
    "            data=tabular_model.datamodule._prepare_inference_data(valid),\n",
    "            categorical_cols=tabular_model.datamodule.config.categorical_cols,\n",
    "            continuous_cols=tabular_model.datamodule.config.continuous_cols,\n",
    "            target=\"target\"\n",
    ")\n",
    "\n",
    "test_tabular_dataset = TabularDataset(\n",
    "            task=tabular_model.datamodule.config.task,\n",
    "            data=tabular_model.datamodule._prepare_inference_data(test),\n",
    "            categorical_cols=tabular_model.datamodule.config.categorical_cols,\n",
    "            continuous_cols=tabular_model.datamodule.config.continuous_cols,\n",
    "            target=\"target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "799e045d-d97b-4bc9-aeb2-a559d53d661f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': array([0], dtype=int64),\n",
       " 'continuous': array([ 4.432042 , -0.6699225], dtype=float32),\n",
       " 'categorical': array([ 1, 67,  1,  1,  1,  2,  2,  1,  1,  2,  1], dtype=int64)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_tabular_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9afb232-82cd-42f1-800c-1220e5d09f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"vacancy_description\"\n",
    "target  = \"target\"\n",
    "train_data = CustomVacancyDataset(train.reset_index(drop=True), train_tabular_dataset, tokenizer, device, text, target, \"train\")\n",
    "valid_data = CustomVacancyDataset(valid.reset_index(drop=True), valid_tabular_dataset, tokenizer, device, text, target, \"valid\")\n",
    "test_data = CustomVacancyDataset(test.reset_index(drop=True), test_tabular_dataset, tokenizer, device, text, target, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c4b4810-48c8-420e-b1f0-5024977f2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data, label, tabular_data = list(zip(*data))\n",
    "    tabular_keys = list(tabular_data[0].keys())\n",
    "    tabular_res = {key: [] for key in tabular_keys}\n",
    "    # print(tabular_data)\n",
    "    for tabular in tabular_data:\n",
    "        for key in tabular_keys:\n",
    "            tabular_res[key].append(tabular[key])\n",
    "    \n",
    "    for key in tabular_keys:\n",
    "        if key == \"target\" or key == \"categorical\":\n",
    "            tabular_res[key] = torch.Tensor(tabular_res[key]).long()\n",
    "        else:\n",
    "            tabular_res[key] = torch.Tensor(tabular_res[key])\n",
    "    return data, torch.stack(label), tabular_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cefab85e-8e97-484e-919f-fb9dfa4c43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c868e-c11c-458d-9523-8cef41e441e6",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6afb0f6c-8a06-45cd-9358-3a0841248b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fafe6efd-270b-45ad-9b56-52367db6fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbedder(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "\n",
    "        self.seq_0 = nn.Sequential(\n",
    "            nn.Linear(312, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.bert(**inputs)\n",
    "        x = (x[\"last_hidden_state\"] * inputs[\"attention_mask\"][:, :, None]).sum(dim=1) / inputs[\"attention_mask\"][:, :, None].sum(dim=1)\n",
    "        x = self.seq_0(torch.mean(x, dim=0))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbadf44-c2b4-40ac-891a-ef1b5b2f3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassification(nn.Module):\n",
    "    def __init__(self, embedder, path2model: str):\n",
    "        super().__init__()\n",
    "        self.embedder = embedder\n",
    "        self.tabular_model = torch.load(path2model)\n",
    "\n",
    "        self.seq_0 = nn.Sequential(\n",
    "            nn.Linear(344, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs, tabular_data: Dict):\n",
    "        temp_x = []\n",
    "        for inp in inputs:\n",
    "            # print(inp.sha)\n",
    "            temp_x.append(self.embedder(inp))\n",
    "        x = torch.stack(temp_x)\n",
    "        # print(x.shape)\n",
    "        tabular_x = self.tabular_model(tabular_data)[\"backbone_features\"]\n",
    "        \n",
    "        x = torch.cat((x, tabular_x), dim=1)\n",
    "        x = self.seq_0(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4564f07-a401-41a0-b58a-8e004542830a",
   "metadata": {},
   "source": [
    "# Define train and and eval function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78453be-3b4b-4e7b-a9e1-8c21ed1b36e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "574e0ffb-fac7-444d-bde8-2c8695423c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    macro_prec, micro_prec = precision_score(y_true, y_pred, average=\"macro\"), precision_score(y_true, y_pred, average=\"micro\")\n",
    "    macro_rec = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    \n",
    "    return macro_f1, macro_prec, macro_rec, micro_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8602f3-206e-47c6-9d88-d09df5003c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, loss, data, optimizer):\n",
    "    model.train()\n",
    "    metrics = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "\n",
    "    for i, batch in enumerate(tqdm(data, leave=False, desc=\"Train\")):\n",
    "        tokens_list, target, tabular_data = batch\n",
    "        for key in tabular_data.keys():\n",
    "            tabular_data[key] = tabular_data[key].to(device)\n",
    "        target = target.to(device)\n",
    "        temp_outputs = []\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tokens_list, tabular_data)\n",
    "        loss_remains = loss(outputs, target)\n",
    "        loss_remains.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics += loss_remains.item()\n",
    "        y_pred.append(outputs.to(\"cpu\").detach().numpy().argmax(1))\n",
    "        y_true.append(target.to(\"cpu\").detach().numpy())\n",
    "\n",
    "    metrics /= len(data)\n",
    "\n",
    "    return metrics, np.hstack(y_pred), np.hstack(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b12b1c-a130-4ce6-9937-d19726580db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, loss, data):\n",
    "    model.eval()\n",
    "    metrics = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data, leave=False, desc=\"Eval\"):\n",
    "            tokens_list, target, tabular_data = batch\n",
    "            for key in tabular_data.keys():\n",
    "                tabular_data[key] = tabular_data[key].to(device)\n",
    "            target = target.to(device)\n",
    "    \n",
    "            outputs = model(tokens_list, tabular_data)\n",
    "            loss_remains = loss(outputs, target)\n",
    "\n",
    "            metrics += loss_remains.item()\n",
    "            y_pred.append(outputs.to(\"cpu\").detach().numpy().argmax(1))\n",
    "            y_true.append(target.to(\"cpu\").detach().numpy())\n",
    "            \n",
    "    metrics /= len(data)\n",
    "    \n",
    "    return metrics, np.hstack(y_pred), np.hstack(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6beb0767-f790-46d9-b52d-ed62f410f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss, optimizer, scheduler, train_loader, valid_loader, device, epochs):\n",
    "    info = \"Epoch: %s Train loss: %.3f Valid loss: %.3f\"\n",
    "    best_macro = 0.0\n",
    "    best_micro_precision_score = 0.0\n",
    "    info_metrics = \"Macro f1: %.3f | Macro precision: %.3f | Macro recall: %.3f | Micro precision: %.3f\"\n",
    "    \n",
    "    for epoch in trange(epochs):\n",
    "        train_loss, y_train_pred, y_train_true = train_fn(model, loss, train_loader, optimizer)\n",
    "        eval_loss, y_eval_pred, y_eval_true = eval_fn(model, loss, valid_loader)\n",
    "        \n",
    "        train_metrics = get_score(y_train_true, y_train_pred)\n",
    "        eval_metrics = get_score(y_eval_true, y_eval_pred)\n",
    "        print(info_metrics % train_metrics , \"-- train\")\n",
    "        print(info_metrics % eval_metrics, \"-- eval\")\n",
    "        \n",
    "        if best_macro < sum(eval_metrics[:3]) / 3:\n",
    "            best_macro = sum(eval_metrics[:3]) / 3\n",
    "            torch.save(model.state_dict(), f\"./models/model_best_macro_{best_macro:.4f}.pt\")\n",
    "\n",
    "        if best_micro_precision_score < eval_metrics[-1]:\n",
    "            best_micro_precision_score = eval_metrics[-1]\n",
    "            torch.save(model.state_dict(), f\"./models/model_best_micro_{best_micro_precision_score:.4f}.pt\")\n",
    "            \n",
    "        \n",
    "        print(info % (epoch + 1, train_loss, eval_loss), \"\\n\")\n",
    "        scheduler.step()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    print(best_macro, best_micro_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c2ad0-1466-4632-ac8e-3e9195e4bea9",
   "metadata": {},
   "source": [
    "## Start train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6e3697b-73b3-43fe-afdf-0fc158b24ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model =  AutoModel.from_pretrained(model_name)\n",
    "embedder = BertEmbedder(bert_model)\n",
    "embedder.load_state_dict(torch.load(\"models/model_best_val_macro_0.4499.pt\"))\n",
    "embedder.seq_0 = Identity()\n",
    "\n",
    "model = BertClassification(embedder, path2model=\"./saved_models/tabular_tf.pt\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3cac53e-6a49-4d03-83ef-56add3317dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.MSELoss()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr= 2e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1287ff24-334e-48a2-9ff7-67a8be0e458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba08531bd6244b9ad267b6306daf467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/9323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2123 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.389 | Macro precision: 0.441 | Macro recall: 0.362 | Micro precision: 0.921 -- train\n",
      "Macro f1: 0.496 | Macro precision: 0.493 | Macro recall: 0.501 | Micro precision: 0.936 -- eval\n",
      "Epoch: 1 Train loss: 0.223 Valid loss: 0.177 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/9323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.521 | Macro precision: 0.651 | Macro recall: 0.488 | Micro precision: 0.942 -- train\n",
      "Macro f1: 0.559 | Macro precision: 0.631 | Macro recall: 0.538 | Micro precision: 0.935 -- eval\n",
      "Epoch: 2 Train loss: 0.160 Valid loss: 0.185 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/9323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.585 | Macro precision: 0.650 | Macro recall: 0.551 | Micro precision: 0.954 -- train\n",
      "Macro f1: 0.555 | Macro precision: 0.602 | Macro recall: 0.521 | Micro precision: 0.934 -- eval\n",
      "Epoch: 3 Train loss: 0.130 Valid loss: 0.200 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/9323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.619 | Macro precision: 0.660 | Macro recall: 0.593 | Micro precision: 0.963 -- train\n",
      "Macro f1: 0.535 | Macro precision: 0.622 | Macro recall: 0.480 | Micro precision: 0.932 -- eval\n",
      "Epoch: 4 Train loss: 0.106 Valid loss: 0.224 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/9323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.669 | Macro precision: 0.797 | Macro recall: 0.648 | Micro precision: 0.970 -- train\n",
      "Macro f1: 0.554 | Macro precision: 0.619 | Macro recall: 0.507 | Micro precision: 0.932 -- eval\n",
      "Epoch: 5 Train loss: 0.088 Valid loss: 0.237 \n",
      "\n",
      "0.5758899987715654 0.9362743454795347\n"
     ]
    }
   ],
   "source": [
    "fit(model, loss, optimizer, scheduler, train_loader, valid_loader, device, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67104fcf-3eba-4319-a2c3-db07b9eddb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.5250401724561375, 0.599586736641757, 0.4777998630010968, 0.9340305711987128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss, y_eval_pred, y_eval_true = eval_fn(model, loss, test_loader)\n",
    "eval_metrics = get_score(y_eval_true, y_eval_pred)\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a9135-8fd6-481b-9dd2-db51e1f35c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "583f39f2-55ae-4502-a778-faef2daaaa46",
   "metadata": {},
   "source": [
    "## Other expirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3509cb2-fc87-4ed3-b7ce-ed9593b7e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounder(value: int):\n",
    "    value = int(value)\n",
    "    value_len = len(str(int(value)))\n",
    "    if value_len % 3 == 0:\n",
    "        value_part = value_len // 3 + 1\n",
    "    else:\n",
    "        value_part = value_len // 3 + 2\n",
    "    \n",
    "    right_part = int(value) % 10**value_part\n",
    "    if right_part == 0:\n",
    "        return value\n",
    "    result = (value // 10**value_part + 1) * 10**value_part\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c2deaa-abca-4de7-83f8-768261da4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[df[\"salary_from_rub\"].isna()].index, \"salary_from_rub\"] = df[df[\"salary_from_rub\"].isna()][\"salary_to_rub\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b051826-753f-4bff-a256-9df446b6568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[df[\"salary_to_rub\"].isna()].index, \"salary_to_rub\"] = df[df[\"salary_to_rub\"].isna()][\"salary_from_rub\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bad3692-8d2c-4960-aa9d-3fc0ca2968ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"salary_from_rub_rounded\"] = df[\"salary_from_rub\"].apply(lambda x: rounder(x))\n",
    "df[\"salary_to_rub_rounded\"] = df[\"salary_to_rub\"].apply(lambda x: rounder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "508f0e17-75ce-4316-9b7e-a1d27eca1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target_rounded\"] = (df[\"salary_from_rub_rounded\"] + df[\"salary_to_rub_rounded\"]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f597903-a945-4946-ba24-45495a91e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_from = df[\"target_rounded\"].dropna().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a6e153f-13e5-4f9f-ac57-c9d87f0930a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_mapped = {}\n",
    "step = 100_000\n",
    "salary_max = 600_000\n",
    "\n",
    "salary_list = sorted(list(set(salary_from.tolist())))\n",
    "last_right_salary = salary_list[0] + step\n",
    "salary_mapped[(salary_list[0], last_right_salary)] = 0\n",
    "last_idx = 0\n",
    "\n",
    "temp_list = []\n",
    "while last_idx < len(salary_list):\n",
    "    salary_part_list = salary_list[last_idx:]\n",
    "    for i, value in enumerate(salary_part_list):\n",
    "        if value >= salary_max:\n",
    "            salary_mapped[(temp_list[-1], value)] = len(salary_mapped)\n",
    "            break\n",
    "        if last_right_salary <= value:\n",
    "            if temp_list:\n",
    "                salary_mapped[(temp_list[-1], value)] = len(salary_mapped)\n",
    "            temp_list.append(value)\n",
    "            break\n",
    "    if value >= salary_max:\n",
    "        break\n",
    "    last_right_salary += step\n",
    "    last_idx += i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70570da-8fe7-4e77-bc36-68a624dea849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_mapper(x):\n",
    "    for (left_salary, right_salary), idx in salary_mapped.items():\n",
    "        if left_salary <= x and x <= right_salary:\n",
    "            return idx\n",
    "    return idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64db783-42f4-4223-9c02-203988f609c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"target_rounded\"].apply(lambda x: salary_mapper(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49941ff0-f8b1-4af4-8498-10d6ac118137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    300591\n",
       "1     63054\n",
       "2      6933\n",
       "3      1396\n",
       "4       548\n",
       "6       184\n",
       "5       184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "047f2100-d3b0-446e-aaee-aedbae352d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"vacancy_name_score\", \"vacancy_name_len\"]\n",
    "categorical_features = [\n",
    "                        \"work_schedule\", \"city\", \"accredit_it\", \"state\",\n",
    "                        \"salary_currency\", \"salary_gross\", \"vacancy_experience\", \"vacancy_type\", \"created_quarter\",\n",
    "                        \"created_month\", \"trusted\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74c51b9-a274-473a-886d-43a9580f01ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:12</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">963</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:12\u001b[0m,\u001b[1;36m963\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:13\u001b[0m,\u001b[1;36m237\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">829</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:13\u001b[0m,\u001b[1;36m829\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\tabular_datamodule.py:368: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.02889218 -0.66992245  1.13661739 ... -0.02889218  0.32076069\n",
      "  1.13661739]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.07834191 -0.55337149  0.5538626  ...  0.26248521  1.31144383\n",
      " -0.72819793]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">632</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: FTTransformerModel     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:15\u001b[0m,\u001b[1;36m632\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: FTTransformerModel     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">156</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:17\u001b[0m,\u001b[1;36m156\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">577</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:17\u001b[0m,\u001b[1;36m577\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m630\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory saved_models exists and is not empty.\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ce5bc35c9047cfae6cf1bb7597fa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.0005248074602497723\n",
      "Restoring states from the checkpoint path at D:\\pd\\ML_part\\.lr_find_5dabd5a0-eba2-4985-ad80-654f7130c5de.ckpt\n",
      "Restored all states from the checkpoint at D:\\pd\\ML_part\\.lr_find_5dabd5a0-eba2-4985-ad80-654f7130c5de.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">468</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0005248074602497723</span>. For    \n",
       "plot and detailed analysis, use `find_learning_rate` method.                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:44\u001b[0m,\u001b[1;36m468\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m643\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.0005248074602497723\u001b[0m. For    \n",
       "plot and detailed analysis, use `find_learning_rate` method.                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">472</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:59:44\u001b[0m,\u001b[1;36m472\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ custom_loss      │ CrossEntropyLoss      │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ FTTransformerBackbone │ 86.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _embedding_layer │ Embedding2dLayer      │  150 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ _head            │ LinearHead            │    231 │\n",
       "└───┴──────────────────┴───────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ custom_loss      │ CrossEntropyLoss      │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ FTTransformerBackbone │ 86.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding2dLayer      │  150 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead            │    231 │\n",
       "└───┴──────────────────┴───────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 237 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 237 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 237 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 237 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39760b25f9f5439fa496e9c40ae7db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">672</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:18\u001b[0m,\u001b[1;36m672\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:18\u001b[0m,\u001b[1;36m674\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3058186f62884be093181fc82133554c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.43731165 -1.01957532  0.08765877 ...  0.96179095  0.78696452\n",
      " -0.61164697]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8415794968605042     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8415794968605042     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5002081990242004     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8415794968605042    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8415794968605042    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5002081990242004    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "D:\\pd\\ML_part\\venv\\lib\\site-packages\\pytorch_tabular\\tabular_datamodule.py:372: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.43731165 -1.01957532  0.08765877 ...  0.96179095  0.78696452\n",
      " -0.61164697]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        \"target\"\n",
    "    ],  # target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=numeric_features,\n",
    "    categorical_cols=categorical_features,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\",  # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    ").__dict__\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    num_attn_blocks=3,\n",
    "    num_heads=4,\n",
    "    learning_rate=1e-3,\n",
    "    head=\"LinearHead\",\n",
    "    head_config=head_config,\n",
    "    metrics=[\"f1_score\",\"accuracy\"], \n",
    "    metrics_params=[{\"num_classes\":7},{}]\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "# sampler = get_balanced_sampler(train['target'].values.ravel())\n",
    "loss = weighted_loss = get_class_weighted_cross_entropy(train[\"target\"].values.ravel(), mu=0.1)\n",
    "\n",
    "tabular_model.fit(train=train, validation=valid, loss=loss)\n",
    "result = tabular_model.evaluate(test)\n",
    "pred_df = tabular_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e570c08-8543-4ac6-8bf6-8f6fc4afa6d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92d26ce3-c0b3-48e2-a7a9-c144b625080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31eacf17-ff33-4344-b352-1b9bc9dadef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.load(\"./saved_models/tabular_tf.pt\")(next(iter(example_loader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3091a457-0dfa-4c52-b95a-7ec56d76f652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6267dcc-2511-47d9-b7b7-fd8078440ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 7])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.model(next(iter(example_loader)))[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ceaff-fbd9-4995-bf7d-fa9db07e9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model.model(next(iter(example_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bb1e8c7-b5c8-4959-bce4-e7634bbfd251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logits', torch.Size([32, 7])), ('backbone_features', torch.Size([32, 32]))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, values.shape) for key, values in tabular_model.model(next(iter(example_loader))).items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d0a400d-1ec7-477e-b75a-c5cf1c7ee1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.save_model_for_inference(path=\"./saved_models/tabular_tf.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cfa9ba1-1302-405a-893e-d94ac4ba3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1986850779206854,\n",
       " 0.1897519092581868,\n",
       " 0.2721189454291428,\n",
       " 0.8427192276749799)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(pred_df[\"prediction\"], test[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55d39f2f-86a6-4fd0-b9ea-98f446938baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1941162831619823,\n",
       " 0.3911969928098954,\n",
       " 0.20373587603129048,\n",
       " 0.6652587825154197)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(pred_df[\"prediction\"], test[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d54044b-1f9b-4090-86dc-343700d695c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16070326331854282,\n",
       " 0.3371015636209266,\n",
       " 0.1962906118179383,\n",
       " 0.5799141861088764)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(pred_df[\"prediction\"], test[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c48245a-52ff-44e5-8f98-11c398dd6d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29390811612969536,\n",
       " 0.28408295060416433,\n",
       " 0.35327816163110254,\n",
       " 0.8415795119334942)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(pred_df[\"prediction\"], test[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc28dc50-af15-44d9-8dec-150d22cb694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "0    11643\n",
       "1      889\n",
       "2       13\n",
       "3        4\n",
       "4        2\n",
       "6        1\n",
       "5        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[pred_df[\"prediction\"] == test[\"target\"]][\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34ad1399-6532-45cc-9636-8ed96919bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "0    1733\n",
       "1     557\n",
       "2      28\n",
       "3      20\n",
       "4      16\n",
       "5       6\n",
       "6       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[pred_df[\"prediction\"] != test[\"target\"]][\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e1b26d6-7403-48e9-af44-65aa63031ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./saved_models/tabular_class.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tabular_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cf4337e-19c3-4051-9d83-a1b1e4093329",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(bert_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetWithLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m TripletLossWithMiner(margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, miner\u001b[38;5;241m=\u001b[39mAllTripletsMiner(), need_logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m sampler \u001b[38;5;241m=\u001b[39m BalanceSampler(train_dataset\u001b[38;5;241m.\u001b[39mget_labels(), n_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_instances\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mD:\\pd\\ML_part\\venv\\lib\\site-packages\\oml\\datasets\\base.py:104\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[1;34m(self, df, extra_data, transform, dataset_root, f_imread, cache_size, input_tensors_key, labels_key, paths_key, categories_key, sequence_key, x1_key, x2_key, y1_key, y2_key, index_key)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28mlen\u001b[39m(record) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m extra_data\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    102\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll the extra records need to have the size equal to the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (LABELS_COLUMN, PATHS_COLUMN))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_tensors_key \u001b[38;5;241m=\u001b[39m input_tensors_key\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_key \u001b[38;5;241m=\u001b[39m labels_key\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(bert_model.parameters(), lr=1e-6)\n",
    "\n",
    "train_dataset = DatasetWithLabels(df=train[numeric_features + categorical_features + [\"target\"]], dataset_root=\"./\")\n",
    "criterion = TripletLossWithMiner(margin=0.1, miner=AllTripletsMiner(), need_logs=True)\n",
    "sampler = BalanceSampler(train_dataset.get_labels(), n_labels=2, n_instances=2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=sampler)\n",
    "\n",
    "for batch in tqdm(train_loader):\n",
    "    embeddings = extractor(batch[\"input_tensors\"])\n",
    "    loss = criterion(embeddings, batch[\"labels\"])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # info for logging: positive/negative distances, number of active triplets\n",
    "    print(criterion.last_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b12339a-0a0e-4983-b859-febcaebdf9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151428    0\n",
       "66476     0\n",
       "26240     1\n",
       "203706    0\n",
       "28384     0\n",
       "         ..\n",
       "117584    0\n",
       "287411    0\n",
       "11528     0\n",
       "313222    2\n",
       "365703    1\n",
       "Name: target, Length: 298312, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5f488-bb94-4ae4-84ef-bfad9b83fa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7774c-68e3-4a4d-8b96-56341aa3e6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d61b1c-6ded-4eae-9b7e-ae43765e2598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
